{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Encoding and Variational Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, two different methods of data encoding are compared in their implementation and performance. These encoding methods are Angle and Amplitude Encoding, respectively. These methods are then used in the training and testing of a mock dataset in a Variational Quantum Classifier. This work is done using the PennyLane SDK along with Pandas and SKLearn for the initial data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation Cell\n",
    "\n",
    "import pandas as pd\n",
    "from pennylane import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import BasisEmbedding, AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the appropriate libraries have been imported, the data can be loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the datasets being arbitrary mock sets, there isn't much data analysis required, but rather just the surface-level analysis of the dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('mock_train_set.csv')\n",
    "test_set = pd.read_csv('mock_test_set.csv')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2789.26</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4040.01</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2931.20</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3896.54</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>982.06</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1         2     3    4\n",
       "0  2789.26     1000.0      10.0  20.0  0.0\n",
       "1  4040.01  1000000.0       1.0   1.0  1.0\n",
       "2  2931.20    10000.0   10000.0  40.0  1.0\n",
       "3  3896.54    10000.0  100000.0  30.0  1.0\n",
       "4   982.06      100.0    1000.0  75.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2988.55</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3413.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3891.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4514.99</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>752.29</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1          2     3    4\n",
       "0  2988.55  10000.0    10000.0  75.0  1.0\n",
       "1  3413.80      1.0      100.0  90.0  0.0\n",
       "2  3891.52      1.0        1.0   5.0  0.0\n",
       "3  4514.99  10000.0  1000000.0  25.0  1.0\n",
       "4   752.29     10.0       10.0  90.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set[['0', '1', '2', '3']]\n",
    "y_train = train_set[['4']]\n",
    "\n",
    "x_test = test_set[['0', '1', '2', '3']]\n",
    "y_test = test_set[['4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (300, 4)\n",
      "Test Shape : (120, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape: {}\\nTest Shape : {}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.41304389e-01 3.37474595e-01 3.37474595e-03 6.74949190e-03]\n",
      " [4.03997703e-03 9.99991839e-01 9.99991839e-07 9.99991839e-07]\n",
      " [2.02952793e-01 6.92388075e-01 6.92388075e-01 2.76955230e-03]\n",
      " ...\n",
      " [9.99879222e-01 2.39044858e-04 2.39044858e-04 1.55379158e-02]\n",
      " [2.97282715e-01 9.54741758e-01 9.54741758e-03 9.54741758e-05]\n",
      " [4.54021346e-02 9.94010701e-02 9.94010701e-01 8.94609631e-04]]\n"
     ]
    }
   ],
   "source": [
    "data = normalize(x_train)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been loaded and formatted in normalised dataframes, so now the quantum part of the project can begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational quantum classifiers follow a very simple framework to produce the output predictions from input data. The model begins with an encoding block, which is how the input data is converted to be stored in qubits. After the encoding, there is a block of rotation and entangling gates, which contain the parameters (weights) which define the dials of the model and how the qubits communicate through correlation. The final step is to measure the qubits in the computational basis to have an output expectation value corresponding to the classification task. The dataset in this project has a binary target, which makes the measurement a simple correspondence to the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method of encoding used is that of Angle Encoding, which converts normalised data into rotations of a set of qubits by an angle reflecting the magnitude of each data entry. The number of qubits required scales with the number of input dimensions for each data entry. For example, the dataset in this project has 4 dimensions of input data, which requires 4 qubits to encode, with each block being a parallel set of rotation gates of the normalised data, repeated in series for each entry in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = data.shape[1]\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    # Apply Hadamards to all qubits in the circuit\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the encoding of data, there is the process of parameterising the circuit. This is done through a set of rotation gates with the parameters of weights which the model needs to train. The number of rotation gates corresponds to the number of qubits used, however that is typically not enough complexity for a good model, so these blocks of rotation gates are repeated. In between these rotation blocks, there are sets of entangling CNOT gates, to fully make use of quantum interference and correlation. The architecture of these parameterisation blocks is arbitrary and depends on the model being built, so in this case the `StronglyEntanglingLayers` format is used, which can be found here: https://pennylane.readthedocs.io/en/stable/code/api/pennylane.StronglyEntanglingLayers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the weights and bias of the ML model can be initialised as random values with the appropriate shape for the quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00496714 -0.00138264  0.00647689]\n",
      "  [ 0.0152303  -0.00234153 -0.00234137]\n",
      "  [ 0.01579213  0.00767435 -0.00469474]\n",
      "  [ 0.0054256  -0.00463418 -0.0046573 ]]\n",
      "\n",
      " [[ 0.00241962 -0.0191328  -0.01724918]\n",
      "  [-0.00562288 -0.01012831  0.00314247]\n",
      "  [-0.00908024 -0.01412304  0.01465649]\n",
      "  [-0.00225776  0.00067528 -0.01424748]]\n",
      "\n",
      " [[-0.00544383  0.00110923 -0.01150994]\n",
      "  [ 0.00375698 -0.00600639 -0.00291694]\n",
      "  [-0.00601707  0.01852278 -0.00013497]\n",
      "  [-0.01057711  0.00822545 -0.01220844]]\n",
      "\n",
      " [[ 0.00208864 -0.0195967  -0.01328186]\n",
      "  [ 0.00196861  0.00738467  0.00171368]\n",
      "  [-0.00115648 -0.00301104 -0.01478522]\n",
      "  [-0.00719844 -0.00460639  0.01057122]]\n",
      "\n",
      " [[ 0.00343618 -0.0176304   0.00324084]\n",
      "  [-0.00385082 -0.00676922  0.00611676]\n",
      "  [ 0.01031     0.0093128  -0.00839218]\n",
      "  [-0.00309212  0.00331263  0.00975545]]\n",
      "\n",
      " [[-0.00479174 -0.00185659 -0.01106335]\n",
      "  [-0.01196207  0.00812526  0.0135624 ]\n",
      "  [-0.0007201   0.01003533  0.00361636]\n",
      "  [-0.0064512   0.00361396  0.01538037]]\n",
      "\n",
      " [[-0.00035826  0.01564644 -0.02619745]\n",
      "  [ 0.00821903  0.00087047 -0.00299007]\n",
      "  [ 0.00091761 -0.01987569 -0.00219672]\n",
      "  [ 0.00357113  0.01477894 -0.0051827 ]]\n",
      "\n",
      " [[-0.00808494 -0.00501757  0.00915402]\n",
      "  [ 0.00328751 -0.0052976   0.00513267]\n",
      "  [ 0.00097078  0.00968645 -0.00702053]\n",
      "  [-0.00327662 -0.00392108 -0.01463515]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "num_layers = 8\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.01118875, requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantum circuit for the Variational Quantum Classifier has now been created, and the classical component of the model needs to be constructed. The output of the quantum circuit needs to be converted back to a classical value, which can then be used as an input to a cost function to measure how close the generated predictions are to the actual training set targets. The cost function used here is a simple square loss, which is standard convention in most machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier for the classifier, the target data needs to be shifted to align better with the output of the quantum circuit. The quanutm circuit as a binary classifier will return expectation values of the final qubit states which are projections onto the Z-axis of a Block Sphere, which has a positive or negative value. So, the data can be interpreted as falling into one of two classes defined by 1 and -1, indicating their \"spin orientation\" which can be expressed in the binary (0, 1) target values by shifting each 0 to become -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(0.94130439, requires_grad=False), tensor(0.3374746, requires_grad=False), tensor(0.00337475, requires_grad=False), tensor(0.00674949, requires_grad=False)], Y = -1\n",
      "X = [tensor(0.00403998, requires_grad=False), tensor(0.99999184, requires_grad=False), tensor(9.99991839e-07, requires_grad=False), tensor(9.99991839e-07, requires_grad=False)], Y =  1\n",
      "X = [tensor(0.20295279, requires_grad=False), tensor(0.69238808, requires_grad=False), tensor(0.69238808, requires_grad=False), tensor(0.00276955, requires_grad=False)], Y =  1\n",
      "X = [tensor(0.03874291, requires_grad=False), tensor(0.09942901, requires_grad=False), tensor(0.99429008, requires_grad=False), tensor(0.00029829, requires_grad=False)], Y =  1\n",
      "X = [tensor(0.69790787, requires_grad=False), tensor(0.07106571, requires_grad=False), tensor(0.71065706, requires_grad=False), tensor(0.05329928, requires_grad=False)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(y_train.values[:,0] * 2 - np.ones(len(y_train.values[:,0])), requires_grad = False)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(data, requires_grad=False)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training of the circuit, an optimisation function is required to tweak the weights of the circuit in the direction which minimises the difference between the predictions and the training targets. The choice of optimiser is once again an arbitrary choice which depends on the model at hand, and in this case the Adam Optimiser was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can now be trained in batches of data, to improve efficiency, while the results are recorded and the best performing weight sets are saved as the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.9293968 | Accuracy: 0.5233333 \n",
      "Iter:     2 | Cost: 0.8903067 | Accuracy: 0.5233333 \n",
      "New best\n",
      "Iter:     3 | Cost: 0.8323824 | Accuracy: 0.8000000 \n",
      "Iter:     4 | Cost: 0.7628541 | Accuracy: 0.6600000 \n",
      "Iter:     5 | Cost: 0.7338487 | Accuracy: 0.5733333 \n",
      "Iter:     6 | Cost: 0.7772821 | Accuracy: 0.5233333 \n",
      "Iter:     7 | Cost: 0.6650366 | Accuracy: 0.7866667 \n",
      "Iter:     8 | Cost: 0.6862241 | Accuracy: 0.7833333 \n",
      "Iter:     9 | Cost: 0.7203829 | Accuracy: 0.6666667 \n",
      "New best\n",
      "Iter:    10 | Cost: 0.7064974 | Accuracy: 0.8233333 \n",
      "New best\n",
      "Iter:    11 | Cost: 0.7261132 | Accuracy: 0.8300000 \n",
      "Iter:    12 | Cost: 0.6396183 | Accuracy: 0.8300000 \n",
      "Iter:    13 | Cost: 0.5921352 | Accuracy: 0.8266667 \n",
      "Iter:    14 | Cost: 0.5848600 | Accuracy: 0.8133333 \n",
      "New best\n",
      "Iter:    15 | Cost: 0.5624528 | Accuracy: 0.8366667 \n",
      "Iter:    16 | Cost: 0.6011162 | Accuracy: 0.8300000 \n",
      "Iter:    17 | Cost: 0.5742933 | Accuracy: 0.8300000 \n",
      "Iter:    18 | Cost: 0.5638761 | Accuracy: 0.8233333 \n",
      "Iter:    19 | Cost: 0.5527054 | Accuracy: 0.8300000 \n",
      "Iter:    20 | Cost: 0.5696337 | Accuracy: 0.8300000 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "\n",
    "for it in range(20):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "    \n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers nor optimizer make any difference, accuracy peaks at ~83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(y_test.values[:,0] * 2 - np.ones(len(y_test.values[:,0])), requires_grad = False)\n",
    "Xte = np.array(normalize(x_test), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.2821542255428317, Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions  Test\n",
       "0           1.0   1.0\n",
       "1          -1.0  -1.0\n",
       "2          -1.0  -1.0\n",
       "3           1.0   1.0\n",
       "4          -1.0  -1.0\n",
       "..          ...   ...\n",
       "115         1.0   1.0\n",
       "116        -1.0  -1.0\n",
       "117        -1.0  -1.0\n",
       "118        -1.0  -1.0\n",
       "119        -1.0  -1.0\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((predictions, Yte), ('Predictions', 'Test')).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the training process reached a plateau at an accuracy score of ~83%, which is not ideal but still good enough to work with. The optimal parameters are shown to be very effective when generating predictions for the test set, which has an accuracy of 100%. This shows perfect operation of the trained model on the test set. The model could be improved by batching and testing on different combinations of train/test sets, however this mock dataset is just being used to show the process of building a Variational Quantum Classifier, so it serves its purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model, a nearly identical process is followed, with the only change being in the data encoding scheme which is this time the Amplitude Encoding method. This method makes use of the exponential gain in information size of qubits vs classical bits, as it can encode $2^n$ features into an amplitude vector of $n$ qubits. Each quantum state has a normalised probability of being in each of its component states, so in this method the features of the data set can be encoded into the wavefunction of the qubits as the associated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude Encoding\n",
    "\n",
    "num_qubits = int(np.log2(data.ravel().shape)) + 1\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    \n",
    "    AmplitudeEmbedding(features = data, wires = range(num_qubits), normalize = True, pad_with = 0)\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "        \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-7.51179425e-03 -1.13042805e-02  7.69977360e-03]\n",
      "  [ 1.26838952e-02  4.24486244e-03  9.40535585e-03]\n",
      "  [-8.67641090e-03  1.45861852e-03 -1.36987106e-02]\n",
      "  [-7.71780749e-03  8.78673548e-03 -2.39594508e-03]\n",
      "  [ 1.20938197e-02  5.37960004e-03  2.73442216e-02]\n",
      "  [ 9.37654302e-04 -1.40640527e-02 -3.45296561e-04]\n",
      "  [-9.63015626e-03  9.77180001e-03  4.19800645e-04]\n",
      "  [-1.37271817e-03 -1.24132389e-03  7.40340818e-03]\n",
      "  [-4.52462232e-03  7.77049795e-03  1.04557117e-02]\n",
      "  [-3.42141713e-03 -9.26046619e-03 -5.12965318e-03]\n",
      "  [ 7.10109240e-03  9.24788716e-04  6.30074939e-03]]\n",
      "\n",
      " [[ 1.76293747e-02  2.30953723e-03 -8.08936891e-03]\n",
      "  [ 1.05742351e-02  5.13608595e-04  8.72447158e-03]\n",
      "  [ 1.06619854e-02 -9.59008096e-03  1.38200460e-02]\n",
      "  [ 9.05121960e-03 -6.03904372e-03  3.04449120e-03]\n",
      "  [ 2.57207491e-03  2.39318145e-04  8.71913989e-03]\n",
      "  [ 1.43735633e-02  7.30637274e-05  1.33088133e-02]\n",
      "  [ 9.88202611e-03  2.32296158e-03  1.76180922e-03]\n",
      "  [-1.15256537e-02 -1.50076839e-02  1.65022798e-03]\n",
      "  [-8.55928918e-03 -3.96361420e-04 -5.34662742e-03]\n",
      "  [-1.78849650e-02  3.57304542e-03 -4.14531805e-03]\n",
      "  [ 8.01987125e-04 -8.93120274e-03 -3.34817247e-03]]\n",
      "\n",
      " [[ 1.56038014e-02  1.28551000e-03  5.49576345e-03]\n",
      "  [-1.27087181e-02  2.38903596e-02  1.84341376e-02]\n",
      "  [ 1.36343549e-02  8.28765978e-03  1.51432783e-04]\n",
      "  [ 4.42074017e-03  1.04801974e-02 -6.28569747e-03]\n",
      "  [-4.44498744e-03 -1.66913236e-02 -7.71819078e-03]\n",
      "  [ 1.66130173e-02 -3.34247091e-03 -3.17846907e-03]\n",
      "  [ 3.17767032e-03 -1.61222731e-02  9.45381690e-03]\n",
      "  [ 1.26640686e-02  3.77296265e-03  1.65135099e-02]\n",
      "  [-1.32683177e-02  1.84371580e-02 -7.30741403e-03]\n",
      "  [-1.27991973e-02 -2.37391961e-03  1.87200568e-02]\n",
      "  [-1.94421409e-04 -9.32591657e-03 -1.29494247e-02]]\n",
      "\n",
      " [[-1.05118505e-03 -1.99496157e-02 -1.30019284e-02]\n",
      "  [ 1.54306765e-02  1.32326381e-02 -1.28412147e-03]\n",
      "  [-4.65664771e-03  5.85089023e-04  2.34799693e-02]\n",
      "  [ 4.04975509e-03  9.09738175e-03 -2.02457526e-03]\n",
      "  [ 6.08966071e-04  6.47162697e-03  1.26094828e-03]\n",
      "  [-1.89737698e-02  1.28054076e-02 -6.15133678e-03]\n",
      "  [ 2.11131764e-02  6.86848513e-03  7.09724156e-04]\n",
      "  [ 4.39327140e-03 -1.08497889e-03 -4.86432766e-03]\n",
      "  [ 2.07598261e-03  8.84990467e-03 -4.64529749e-03]\n",
      "  [-6.22237165e-03 -3.55488641e-03  9.52011094e-03]\n",
      "  [ 1.45255025e-02  3.62013912e-03  5.81314134e-03]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.77070738, requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.5, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 1.3722308 | Accuracy: 0.4766667 \n",
      "Iter:     2 | Cost: 1.0724018 | Accuracy: 0.4766667 \n",
      "Iter:     3 | Cost: 0.9818780 | Accuracy: 0.4766667 \n",
      "New best\n",
      "Iter:     4 | Cost: 1.0404262 | Accuracy: 0.5233333 \n",
      "Iter:     5 | Cost: 1.0376057 | Accuracy: 0.5233333 \n",
      "Iter:     6 | Cost: 1.0839862 | Accuracy: 0.5233333 \n",
      "Iter:     7 | Cost: 1.0133862 | Accuracy: 0.5233333 \n",
      "Iter:     8 | Cost: 1.0152050 | Accuracy: 0.5233333 \n",
      "Iter:     9 | Cost: 0.9669390 | Accuracy: 0.5233333 \n",
      "Iter:    10 | Cost: 0.9753207 | Accuracy: 0.5233333 \n",
      "Iter:    11 | Cost: 0.9721757 | Accuracy: 0.5233333 \n",
      "New best\n",
      "Iter:    12 | Cost: 0.9844758 | Accuracy: 0.5733333 \n",
      "New best\n",
      "Iter:    13 | Cost: 0.9722606 | Accuracy: 0.8300000 \n",
      "Iter:    14 | Cost: 0.9581019 | Accuracy: 0.8133333 \n",
      "Iter:    15 | Cost: 0.9698022 | Accuracy: 0.4766667 \n",
      "Iter:    16 | Cost: 1.0200429 | Accuracy: 0.4766667 \n",
      "Iter:    17 | Cost: 0.9890963 | Accuracy: 0.4766667 \n",
      "Iter:    18 | Cost: 1.0314200 | Accuracy: 0.4766667 \n",
      "Iter:    19 | Cost: 1.0548899 | Accuracy: 0.4766667 \n",
      "Iter:    20 | Cost: 0.8630800 | Accuracy: 0.5266667 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "\n",
    "for it in range(20):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "    \n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(y_test.values[:,0] * 2 - np.ones(len(y_test.values[:,0])), requires_grad = False)\n",
    "Xte = np.array(normalize(x_test), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.9548300323278923, Accuracy: 99.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions  Test\n",
       "0           1.0   1.0\n",
       "1          -1.0  -1.0\n",
       "2          -1.0  -1.0\n",
       "3           1.0   1.0\n",
       "4          -1.0  -1.0\n",
       "..          ...   ...\n",
       "115         1.0   1.0\n",
       "116        -1.0  -1.0\n",
       "117        -1.0  -1.0\n",
       "118        -1.0  -1.0\n",
       "119        -1.0  -1.0\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((predictions, Yte), ('Predictions', 'Test')).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very similar performance is seen in this model, although with slight differences. Firstly, more qubits are required as the necessary circuit size grows as $\\log_2(n)$ with the data entries. Additionally, less entangling layers and weight parameters are required to achieve similar accuracies in training and test validation to make up for the wider quantum circuit required. Techincially, the Angle Encoding model had slightly better performance, however both performed very well and are satisfactory binary classifiers. In practice, the angle encoding model would also be preferable simply due to it requiring fewer qubits, however this is only really a problem of NISQ devices which have limits of the number of qubits which can effectively be used in circuits of modern devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the bare-bones version of this project, which effectively implements two methods of data encoding into quantum circuits and builds nearly equally successful Variational Quantum Classifiers on a mock dataset. The models can expression of the data/results can be significantly improved in future, but for now this does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 6m1s\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "totaltime = end - start\n",
    "\n",
    "mins = int(np.round(totaltime % 60))\n",
    "secs = int(np.round((totaltime % 60 - mins) * 60))\n",
    "\n",
    "print(f'Execution time: {mins}m{secs}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
